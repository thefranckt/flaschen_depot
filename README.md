# ğŸšš Flaschendepot - Service-Time Prediction MLOps

## ğŸ“‹ ProjektÃ¼bersicht

VollstÃ¤ndiges **MLOps-System** fÃ¼r die **Service-Time-Vorhersage** bei GetrÃ¤nkelieferungen.  
Nutzt **1.5 Millionen echte Bestellungen** fÃ¼r Machine Learning Regression.

### ğŸ¯ Ziel
Vorhersage der **Service-Zeit** (Minuten) basierend auf:
- ğŸ“¦ Artikelanzahl & Gewicht
- ğŸ¢ Stockwerk & Aufzug
- ğŸ• Tageszeit & Wochentag  
- ğŸ“ Warehouse & Kundentyp

---

## ğŸ“Š Daten - 4 Parquet-Dateien

| Datei | Zeilen | Beschreibung |
|-------|--------|-------------|
| **articles.parquet** | 15.6M | Artikel mit Gewichten |
| **orders.parquet** | 1.5M | Bestellinformationen |
| **driver_order_mapping.parquet** | 1.5M | Fahrer-Zuordnung |
| **service_times.parquet** â­ | 1.5M | **Service-Zeiten (Target)** |

### Zielvariable
**`service_time_in_minutes`**  
- Min: 0.02 min | Max: 360 min  
- **Median: 8.0 min** | Mean: 9.4 min  
- Regression-Problem

---

## ğŸš€ Quick Start

### 1. Installation

```powershell
# Virtual Environment
python -m venv venv
.\venv\Scripts\activate

# Dependencies
pip install -r requirements.txt
```

### 2. Datenverarbeitung

```powershell
python src\data\make_dataset.py
```

**Was passiert:**
- âœ… LÃ¤dt 4 Parquet-Dateien aus `data/raw/`
- âœ… Merged Ã¼ber `web_order_id`
- âœ… Aggregiert Artikel-Stats (Anzahl, Gewicht)
- âœ… Bereinigt & filtert Daten
- âœ… Train/Test Split (80/20)
- âœ… Speichert in `data/processed/`

**Output**: ~1.2M Training, ~307K Test

### 3. Exploratory Data Analysis

```powershell
jupyter notebook notebooks/01_eda_delivery_service.ipynb
```

**Notebook-Inhalte:**
- ğŸ“Š Service-Time Verteilungen
- ğŸ“ˆ Stockwerk vs Service-Zeit
- ğŸ‹ï¸ Gewicht & Artikelanzahl Impact
- ğŸ• Zeitliche Muster-Analyse
- ğŸ’¡ Key Insights

---

## ğŸ—ï¸ Projekt-Architektur

```
flaschendepot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # 4 Parquet-Dateien hier!
â”‚   â”‚   â”œâ”€â”€ articles.parquet
â”‚   â”‚   â”œâ”€â”€ orders.parquet
â”‚   â”‚   â”œâ”€â”€ driver_order_mapping.parquet
â”‚   â”‚   â””â”€â”€ service_times.parquet
â”‚   â””â”€â”€ processed/              # Train/Test CSVs
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda_delivery_service.ipynb  # Explorative Analyse
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ make_dataset.py     # Daten laden & mergen
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py   # Feature Engineering
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_model.py      # Training (Regression)
â”‚   â”‚   â””â”€â”€ predict.py          # Vorhersagen
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.py             # FastAPI REST API
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # Konfiguration
â”œâ”€â”€ models/                     # Trainierte Modelle
â”œâ”€â”€ tests/                      # Unit Tests
â””â”€â”€ scripts/
    â””â”€â”€ train_pipeline.py       # End-to-End Pipeline
```

---

## ğŸ”¬ Features

### Input-Features

**Kategorisch:**
- `warehouse_id`: Warehouse-Standort
- `has_elevator`: Aufzug vorhanden? (boolean)
- `is_pre_order`: Vorbestellung? (boolean)
- `is_business`: B2B-Kunde? (boolean)

**Numerisch:**
- `floor`: Stockwerk (0-20+)
- `num_articles`: Anzahl Artikel
- `total_weight_g`: Gesamtgewicht in Gramm
- `avg_article_weight_g`: Durchschnittsgewicht
- `max_article_weight_g`: Maximales Artikel-Gewicht

**Zeitlich (aus Timestamps):**
- `hour_of_day`: Stunde (0-23)
- `day_of_week`: Wochentag (0-6)
- `is_weekend`: Wochenende? (0/1)
- `month`: Monat (1-12)

**Abgeleitete Features:**
- `total_weight_kg`: Gewicht in kg
- `difficulty_score`: Schwierigkeits-Score (Stockwerk + Gewicht + Aufzug)
- `order_size_category`: GrÃ¶ÃŸenkategorie (small/medium/large/very_large)

### Target Variable
- **`service_time_in_minutes`**: Service-Zeit in Minuten (Regression!)

---

## ğŸ¤– Machine Learning

### Algorithmen
- Random Forest Regressor
- Gradient Boosting Regressor
- XGBoost Regressor
- LightGBM Regressor

### Metriken
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- RÂ² (R-squared)
- MAPE (Mean Absolute Percentage Error)

### Training

```powershell
# Komplette Pipeline
python scripts\train_pipeline.py

# Nur Training
python src\models\train_model.py
```

---

## ğŸŒ API (FastAPI)

### Server starten

```powershell
uvicorn src.api.main:app --reload
```

### Endpoints

**GET** `/health` - Health Check

**POST** `/predict` - Einzelvorhersage
```json
{
  "warehouse_id": 12,
  "has_elevator": false,
  "floor": 3.0,
  "is_pre_order": true,
  "is_business": false,
  "num_articles": 15,
  "total_weight_g": 25000,
  "hour_of_day": 14,
  "day_of_week": 2
}
```

**Response:**
```json
{
  "predicted_service_time": 11.5,
  "confidence_interval": [9.2, 13.8]
}
```

API Docs: http://localhost:8000/docs

---

## ğŸ³ Docker

```powershell
# Build
docker build -t flaschendepot:latest .

# Run Training
docker run --rm -v ${PWD}/data:/app/data flaschendepot

# Run API
docker-compose up api
```

---

## ğŸ“ˆ MLflow Tracking

```powershell
mlflow ui
```

Ã–ffne: http://localhost:5000

Tracked automatisch:
- Hyperparameter
- Metriken (MAE, RMSE, RÂ²)
- Modelle & Artefakte

---

## ğŸ§ª Testing

```powershell
# Alle Tests
pytest

# Mit Coverage
pytest --cov=src --cov-report=html

# Spezifische Tests
pytest tests/test_data_processing.py
pytest tests/test_models.py
```

---

## ğŸ’¡ Key Insights (aus EDA)

1. **Service-Zeit Durchschnitt**: ~9.4 Minuten (Median: 8.0 min)

2. **Stockwerk-Effekt**:
   - Pro Stockwerk: +0.3-0.5 min
   - Mit Aufzug: ~30% schneller

3. **Gewicht-Impact**:
   - Ab 30kg: Deutlicher Anstieg
   - Linear bis ~50kg, dann exponentiell

4. **Zeitliche Muster**:
   - Peak-Zeiten: 12-14 Uhr & 18-20 Uhr
   - Wochenende: +5-10% lÃ¤ngere Service-Zeit

5. **Artikel-Anzahl**:
   - Moderater Einfluss
   - >20 Artikel: Signifikant lÃ¤nger

---

## ğŸ“š Verwendung

### 1. Datenverarbeitung
```powershell
python src\data\make_dataset.py
```

### 2. Feature Engineering
```powershell
python src\features\build_features.py
```

### 3. Training
```powershell
python src\models\train_model.py
```

### 4. Vorhersagen
```python
from src.models.predict import DeliveryPredictor

predictor = DeliveryPredictor()

delivery_data = {
    'warehouse_id': 12,
    'floor': 3.0,
    'has_elevator': False,
    'num_articles': 15,
    'total_weight_g': 25000,
    'hour_of_day': 14
}

result = predictor.predict_single(delivery_data)
print(f"GeschÃ¤tzte Service-Zeit: {result['prediction']:.1f} Minuten")
```

---

## ğŸ”„ CI/CD Pipeline

GitHub Actions fÃ¼hrt automatisch aus:
- âœ… Tests (Python 3.9, 3.10, 3.11)
- âœ… Linting (black, flake8, isort)
- âœ… Build & Package
- âœ… Docker Image Build

---

## ğŸ“¦ DVC - Data Versioning

```powershell
# Daten tracken
dvc add data/raw/*.parquet
dvc add models/*.pkl

# Commit
git add data/.dvc models/.dvc
git commit -m "Track data and models"

# Push
dvc push
```

---

## ğŸ¯ Projektziele & Use Cases

### Business Value
- â±ï¸ **Bessere Routenplanung** durch genaue ZeitschÃ¤tzungen
- ğŸšš **Effizientere Tourenplanung** fÃ¼r Fahrer
- ğŸ“Š **KapazitÃ¤tsplanung** basierend auf erwarteten Service-Zeiten
- ğŸ’° **Kosteneinsparungen** durch optimierte Routen

### Technical Goals
- âœ… Production-Ready MLOps Pipeline
- âœ… Reproduzierbare Experimente
- âœ… Automatisierte Tests & CI/CD
- âœ… API fÃ¼r Real-Time Predictions
- âœ… Versionierung (Code, Daten, Modelle)

---

## ğŸ‘¤ Autor

**Franz**  
Data Science MLOps Project

---

## ğŸ“ Lizenz

MIT License

---

## ğŸ™ Tech Stack

- **ML**: scikit-learn, XGBoost, LightGBM
- **Data**: pandas, numpy, pyarrow (Parquet)
- **Visualization**: matplotlib, seaborn, plotly
- **MLOps**: MLflow, DVC
- **API**: FastAPI, uvicorn
- **Testing**: pytest
- **CI/CD**: GitHub Actions
- **Containerization**: Docker, Docker Compose

---

**Happy Predicting! ğŸš€ğŸ“¦**
