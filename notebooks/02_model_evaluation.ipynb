{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1eb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import benötigter Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style konfigurieren\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Pfade definieren\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "PLOTS_DIR = Path(\"../plots\")\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Bibliotheken erfolgreich importiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a40fad",
   "metadata": {},
   "source": [
    "## 1. Model und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model laden\n",
    "model_path = MODEL_DIR / \"model_latest.joblib\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"❌ Kein trainiertes Model gefunden!\")\n",
    "    print(f\"   Bitte zuerst 'python train.py' ausführen\")\n",
    "else:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"✓ Model geladen: {model_path}\")\n",
    "    print(f\"  Model Type: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "features_path = DATA_DIR / \"features.parquet\"\n",
    "target_path = DATA_DIR / \"target.parquet\"\n",
    "\n",
    "if not features_path.exists() or not target_path.exists():\n",
    "    print(\"❌ Keine prozessierten Daten gefunden!\")\n",
    "    print(f\"   Bitte zuerst 'python train.py' ausführen\")\n",
    "else:\n",
    "    X = pd.read_parquet(features_path)\n",
    "    y = pd.read_parquet(target_path)['service_time_in_minutes']\n",
    "    \n",
    "    print(f\"✓ Daten geladen\")\n",
    "    print(f\"  Features Shape: {X.shape}\")\n",
    "    print(f\"  Target Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b44e43",
   "metadata": {},
   "source": [
    "## 2. Predictions generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Metriken berechnen\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL PERFORMANCE METRIKEN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE): {rmse:.4f} Minuten\")\n",
    "print(f\"Mean Absolute Error (MAE):      {mae:.4f} Minuten\")\n",
    "print(f\"R² Score:                        {r2:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - Im Durchschnitt weicht die Vorhersage um {mae:.2f} Minuten ab\")\n",
    "print(f\"  - Das Model erklärt {r2*100:.2f}% der Varianz in den Daten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20243378",
   "metadata": {},
   "source": [
    "## 3. Visualisierung 1: Predicted vs Actual\n",
    "\n",
    "Die wichtigste Visualisierung für Regression - zeigt wie gut Predictions mit echten Werten übereinstimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter Plot: Predicted vs Actual\n",
    "axes[0].scatter(y, y_pred, alpha=0.3, s=10)\n",
    "axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Perfekte Vorhersage')\n",
    "axes[0].set_xlabel('Tatsächliche Service Time (Minuten)', fontsize=12)\n",
    "axes[0].set_ylabel('Vorhergesagte Service Time (Minuten)', fontsize=12)\n",
    "axes[0].set_title('Predicted vs Actual Values', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Text mit Metriken\n",
    "textstr = f'RMSE = {rmse:.2f}\\nMAE = {mae:.2f}\\nR² = {r2:.3f}'\n",
    "axes[0].text(0.05, 0.95, textstr, transform=axes[0].transAxes, fontsize=11,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Hexbin Plot (für dichte Bereiche besser sichtbar)\n",
    "hexbin = axes[1].hexbin(y, y_pred, gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "axes[1].plot([y.min(), y.max()], [y.min(), y.max()], 'b--', lw=2, label='Perfekte Vorhersage')\n",
    "axes[1].set_xlabel('Tatsächliche Service Time (Minuten)', fontsize=12)\n",
    "axes[1].set_ylabel('Vorhergesagte Service Time (Minuten)', fontsize=12)\n",
    "axes[1].set_title('Predicted vs Actual (Density)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "plt.colorbar(hexbin, ax=axes[1], label='Anzahl Datenpunkte')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_predicted_vs_actual.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Predicted vs Actual Plot erstellt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6b919",
   "metadata": {},
   "source": [
    "## 4. Visualisierung 2: Residuals (Fehler) Analyse\n",
    "\n",
    "Residuals = Actual - Predicted. Zeigt systematische Fehler im Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals berechnen\n",
    "residuals = y - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Residuals vs Predicted\n",
    "axes[0, 0].scatter(y_pred, residuals, alpha=0.3, s=10)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 0].set_xlabel('Vorhergesagte Service Time (Minuten)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals (Actual - Predicted)', fontsize=11)\n",
    "axes[0, 0].set_title('Residuals vs Predicted Values', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals Histogram\n",
    "axes[0, 1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(x=0, color='r', linestyle='--', lw=2, label='Zero Error')\n",
    "axes[0, 1].axvline(x=residuals.mean(), color='g', linestyle='--', lw=2, label=f'Mean: {residuals.mean():.2f}')\n",
    "axes[0, 1].set_xlabel('Residuals (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Häufigkeit', fontsize=11)\n",
    "axes[0, 1].set_title('Verteilung der Residuals', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Q-Q Plot (prüft Normalverteilung der Fehler)\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot (Normalverteilung der Residuals)', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Absolute Errors\n",
    "abs_errors = np.abs(residuals)\n",
    "axes[1, 1].scatter(y_pred, abs_errors, alpha=0.3, s=10)\n",
    "axes[1, 1].axhline(y=mae, color='r', linestyle='--', lw=2, label=f'MAE: {mae:.2f}')\n",
    "axes[1, 1].set_xlabel('Vorhergesagte Service Time (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Absolute Errors (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_title('Absolute Errors vs Predicted', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_residuals_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Residuals Analyse Plot erstellt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b0b47",
   "metadata": {},
   "source": [
    "## 5. Visualisierung 3: Error Distribution by Ranges\n",
    "\n",
    "Zeigt ob das Model für bestimmte Service Time Bereiche besser/schlechter performt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Time in Bereiche einteilen\n",
    "y_series = pd.Series(y).reset_index(drop=True)\n",
    "bins = [0, 5, 10, 15, 20, 25, 30, 100]\n",
    "labels = ['0-5', '5-10', '10-15', '15-20', '20-25', '25-30', '30+']\n",
    "time_ranges = pd.cut(y_series, bins=bins, labels=labels)\n",
    "\n",
    "# DataFrame für Analyse\n",
    "error_df = pd.DataFrame({\n",
    "    'actual': y_series,\n",
    "    'predicted': y_pred,\n",
    "    'abs_error': np.abs(residuals),\n",
    "    'time_range': time_ranges\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. MAE by Time Range\n",
    "mae_by_range = error_df.groupby('time_range')['abs_error'].mean()\n",
    "axes[0, 0].bar(range(len(mae_by_range)), mae_by_range.values, alpha=0.7, color='steelblue')\n",
    "axes[0, 0].axhline(y=mae, color='r', linestyle='--', lw=2, label=f'Gesamt MAE: {mae:.2f}')\n",
    "axes[0, 0].set_xticks(range(len(mae_by_range)))\n",
    "axes[0, 0].set_xticklabels(mae_by_range.index, rotation=45)\n",
    "axes[0, 0].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Mean Absolute Error (MAE)', fontsize=11)\n",
    "axes[0, 0].set_title('MAE nach Service Time Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Boxplot Errors by Range\n",
    "error_df.boxplot(column='abs_error', by='time_range', ax=axes[0, 1])\n",
    "axes[0, 1].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Absolute Error (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_title('Error Distribution nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].get_figure().suptitle('')  # Remove default title\n",
    "plt.setp(axes[0, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# 3. Sample Count by Range\n",
    "count_by_range = error_df.groupby('time_range').size()\n",
    "axes[1, 0].bar(range(len(count_by_range)), count_by_range.values, alpha=0.7, color='lightcoral')\n",
    "axes[1, 0].set_xticks(range(len(count_by_range)))\n",
    "axes[1, 0].set_xticklabels(count_by_range.index, rotation=45)\n",
    "axes[1, 0].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Anzahl Samples', fontsize=11)\n",
    "axes[1, 0].set_title('Datenverteilung nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. R² by Range (approximation)\n",
    "r2_by_range = error_df.groupby('time_range').apply(\n",
    "    lambda x: r2_score(x['actual'], x['predicted']) if len(x) > 1 else 0\n",
    ")\n",
    "axes[1, 1].bar(range(len(r2_by_range)), r2_by_range.values, alpha=0.7, color='mediumseagreen')\n",
    "axes[1, 1].axhline(y=r2, color='r', linestyle='--', lw=2, label=f'Gesamt R²: {r2:.3f}')\n",
    "axes[1, 1].set_xticks(range(len(r2_by_range)))\n",
    "axes[1, 1].set_xticklabels(r2_by_range.index, rotation=45)\n",
    "axes[1, 1].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('R² Score', fontsize=11)\n",
    "axes[1, 1].set_title('R² Score nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_error_by_ranges.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Error Distribution by Ranges Plot erstellt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbb5e8",
   "metadata": {},
   "source": [
    "## 6. Visualisierung 4: Feature Importance vs Error\n",
    "\n",
    "Analysiert ob schlechte Predictions mit bestimmten Features zusammenhängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926861e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors zu Features hinzufügen\n",
    "X_with_errors = X.copy()\n",
    "X_with_errors['abs_error'] = np.abs(residuals)\n",
    "X_with_errors['predicted'] = y_pred\n",
    "X_with_errors['actual'] = y_series.values\n",
    "\n",
    "# Top 6 wichtigste Features\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance.head(6)['feature'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(top_features):\n",
    "        axes[idx].scatter(X_with_errors[feature], X_with_errors['abs_error'], alpha=0.3, s=10)\n",
    "        axes[idx].axhline(y=mae, color='r', linestyle='--', lw=1, alpha=0.5)\n",
    "        axes[idx].set_xlabel(feature, fontsize=10)\n",
    "        axes[idx].set_ylabel('Absolute Error (Min)', fontsize=10)\n",
    "        axes[idx].set_title(f'{feature} vs Error', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'model_features_vs_error.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Features vs Error Plot erstellt\")\n",
    "else:\n",
    "    print(\"\\n⚠ Model hat keine feature_importances_ (z.B. bei Linear Regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dbd34",
   "metadata": {},
   "source": [
    "## 7. Visualisierung 5: Error Percentiles\n",
    "\n",
    "Zeigt die Verteilung der Errors in Perzentilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ed1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Cumulative Error Distribution\n",
    "sorted_abs_errors = np.sort(np.abs(residuals))\n",
    "cumulative = np.arange(1, len(sorted_abs_errors) + 1) / len(sorted_abs_errors)\n",
    "\n",
    "axes[0].plot(sorted_abs_errors, cumulative * 100, linewidth=2)\n",
    "axes[0].axvline(x=mae, color='r', linestyle='--', lw=2, label=f'MAE: {mae:.2f}')\n",
    "axes[0].axhline(y=50, color='g', linestyle='--', lw=1, alpha=0.5, label='Median (50%)')\n",
    "axes[0].axhline(y=90, color='orange', linestyle='--', lw=1, alpha=0.5, label='90% Percentile')\n",
    "axes[0].set_xlabel('Absolute Error (Minuten)', fontsize=12)\n",
    "axes[0].set_ylabel('Cumulative Percentage', fontsize=12)\n",
    "axes[0].set_title('Kumulative Error Verteilung', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error Percentiles Table\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "error_percentiles = [np.percentile(np.abs(residuals), p) for p in percentiles]\n",
    "\n",
    "axes[1].bar(range(len(percentiles)), error_percentiles, alpha=0.7, color='skyblue')\n",
    "axes[1].set_xticks(range(len(percentiles)))\n",
    "axes[1].set_xticklabels([f'{p}%' for p in percentiles])\n",
    "axes[1].set_xlabel('Percentile', fontsize=12)\n",
    "axes[1].set_ylabel('Absolute Error (Minuten)', fontsize=12)\n",
    "axes[1].set_title('Error Percentiles', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for i, v in enumerate(error_percentiles):\n",
    "    axes[1].text(i, v + 0.3, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_error_percentiles.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Error Percentiles Plot erstellt\")\n",
    "\n",
    "# Percentiles ausgeben\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERROR PERCENTILES\")\n",
    "print(\"=\" * 60)\n",
    "for p, val in zip(percentiles, error_percentiles):\n",
    "    print(f\"{p:3d}% der Predictions haben einen Fehler <= {val:.2f} Minuten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571091c5",
   "metadata": {},
   "source": [
    "## 8. Zusammenfassung\n",
    "\n",
    "Übersicht aller erstellten Visualisierungen und Erkenntnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MODEL EVALUATION - ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. ERSTELLTE VISUALISIERUNGEN:\")\n",
    "print(\"   ✓ Predicted vs Actual (Scatter + Density)\")\n",
    "print(\"   ✓ Residuals Analyse (4 Plots)\")\n",
    "print(\"   ✓ Error Distribution by Time Ranges\")\n",
    "print(\"   ✓ Features vs Error Analysis\")\n",
    "print(\"   ✓ Error Percentiles & Cumulative Distribution\")\n",
    "\n",
    "print(\"\\n2. PERFORMANCE METRIKEN:\")\n",
    "print(f\"   - RMSE: {rmse:.4f} Minuten\")\n",
    "print(f\"   - MAE:  {mae:.4f} Minuten\")\n",
    "print(f\"   - R²:   {r2:.4f}\")\n",
    "\n",
    "print(\"\\n3. ERROR VERTEILUNG:\")\n",
    "print(f\"   - Median Error: {np.median(np.abs(residuals)):.2f} Minuten\")\n",
    "print(f\"   - 90% der Fehler <= {np.percentile(np.abs(residuals), 90):.2f} Minuten\")\n",
    "print(f\"   - Max Error: {np.max(np.abs(residuals)):.2f} Minuten\")\n",
    "\n",
    "print(\"\\n4. INTERPRETATION:\")\n",
    "if r2 > 0.8:\n",
    "    print(\"   ✓ EXCELLENT: Model erklärt > 80% der Varianz\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"   ✓ GOOD: Model erklärt > 60% der Varianz\")\n",
    "elif r2 > 0.4:\n",
    "    print(\"   ⚠ FAIR: Model erklärt > 40% der Varianz\")\n",
    "else:\n",
    "    print(\"   ❌ POOR: Model erklärt < 40% der Varianz\")\n",
    "\n",
    "print(f\"\\n   Im Durchschnitt weicht die Vorhersage um {mae:.2f} Minuten vom echten Wert ab.\")\n",
    "\n",
    "print(\"\\n5. NÄCHSTE SCHRITTE:\")\n",
    "print(\"   - Residuals Analyse prüfen: Gibt es systematische Fehler?\")\n",
    "print(\"   - Q-Q Plot prüfen: Sind Fehler normalverteilt?\")\n",
    "print(\"   - Error by Ranges prüfen: Performt Model überall gleich gut?\")\n",
    "print(\"   - Features vs Error prüfen: Welche Features verursachen große Fehler?\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ EVALUATION ABGESCHLOSSEN\")\n",
    "print(f\"✓ Alle Plots gespeichert in: {PLOTS_DIR}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
