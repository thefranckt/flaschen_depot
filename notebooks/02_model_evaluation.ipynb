{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc1eb54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bibliotheken erfolgreich importiert\n",
      "✓ Pandas version: 2.3.3\n",
      "✓ NumPy version: 2.3.5\n",
      "✓ PyArrow fix applied\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Exécutez cette cellule EN PREMIER après le restart du kernel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fix pyarrow conflict - import in correct order\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Style konfigurieren\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Pfade definieren\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "PLOTS_DIR = Path(\"../plots\")\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Bibliotheken erfolgreich importiert\")\n",
    "print(f\"✓ Pandas version: {pd.__version__}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(f\"✓ PyArrow fix applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c3b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a40fad",
   "metadata": {},
   "source": [
    "## 1. Model und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cbc86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model geladen: ..\\models\\model_latest.joblib\n",
      "  Model Type: LGBMRegressor\n"
     ]
    }
   ],
   "source": [
    "# Model laden\n",
    "model_path = MODEL_DIR / \"model_latest.joblib\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(\"❌ Kein trainiertes Model gefunden!\")\n",
    "    print(f\"   Bitte zuerst 'python train.py' ausführen\")\n",
    "else:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"✓ Model geladen: {model_path}\")\n",
    "    print(f\"  Model Type: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2687ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade 5% Sample der Daten für schnelle Evaluation...\n",
      "✓ Sample geladen: 72,950 Datenpunkte (5%)\n",
      "  Features Shape: (72950, 16)\n",
      "  Target Shape: (72950,)\n",
      "  Zeit: 3.0s\n",
      "✓ Sample geladen: 72,950 Datenpunkte (5%)\n",
      "  Features Shape: (72950, 16)\n",
      "  Target Shape: (72950,)\n",
      "  Zeit: 3.0s\n"
     ]
    }
   ],
   "source": [
    "# Daten laden mit 5% Sample für schnelle Evaluation\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "features_path = DATA_DIR / \"features.parquet\"\n",
    "target_path = DATA_DIR / \"target.parquet\"\n",
    "\n",
    "if not features_path.exists() or not target_path.exists():\n",
    "    print(\"❌ Keine prozessierten Daten gefunden!\")\n",
    "    print(f\"   Bitte zuerst 'python train.py' ausführen\")\n",
    "else:\n",
    "    # OPTIMIERUNG: Lade nur 5% der Daten für schnelle Evaluation\n",
    "    # Verwende fastparquet statt pyarrow um Konflikte zu vermeiden\n",
    "    print(\"Lade 5% Sample der Daten für schnelle Evaluation...\")\n",
    "    \n",
    "    # Lade komplette Daten mit fastparquet engine\n",
    "    X_full = pd.read_parquet(features_path, engine='fastparquet')\n",
    "    y_full = pd.read_parquet(target_path, engine='fastparquet')['service_time_in_minutes']\n",
    "    \n",
    "    # Sample 5% sofort\n",
    "    sample_size = int(len(X_full) * 0.05)\n",
    "    np.random.seed(42)\n",
    "    sample_idx = np.random.choice(len(X_full), sample_size, replace=False)\n",
    "    \n",
    "    X = X_full.iloc[sample_idx].reset_index(drop=True)\n",
    "    y = y_full.iloc[sample_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Freigebe Speicher\n",
    "    del X_full, y_full\n",
    "    \n",
    "    print(f\"✓ Sample geladen: {len(X):,} Datenpunkte (5%)\")\n",
    "    print(f\"  Features Shape: {X.shape}\")\n",
    "    print(f\"  Target Shape: {y.shape}\")\n",
    "    print(f\"  Zeit: {time.time()-start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b44e43",
   "metadata": {},
   "source": [
    "## 2. Predictions generieren & Daten samplen\n",
    "\n",
    "**Optimierung:** Für Visualisierungen nutzen wir 5% Sample (~73k Datenpunkte) - perfekt für schnelle, hochqualitative Plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions generieren\n",
    "print(\"\\nGeneriere Predictions...\")\n",
    "pred_start = time.time()\n",
    "y_pred = model.predict(X)\n",
    "print(f\"✓ Predictions fertig in {time.time()-pred_start:.1f}s\")\n",
    "\n",
    "# Metriken berechnen\n",
    "residuals = y - y_pred\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL PERFORMANCE METRIKEN (5% Sample)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE): {rmse:.4f} Minuten\")\n",
    "print(f\"Mean Absolute Error (MAE):      {mae:.4f} Minuten\")\n",
    "print(f\"R² Score:                        {r2:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - Im Durchschnitt weicht die Vorhersage um {mae:.2f} Minuten ab\")\n",
    "print(f\"  - Das Model erklärt {r2*100:.2f}% der Varianz in den Daten\")\n",
    "print(f\"\\n✓ Gesamt-Zeit bis jetzt: {time.time()-start_time:.1f}s\")\n",
    "\n",
    "# Aliase für Kompatibilität mit restlichem Code\n",
    "X_sample = X\n",
    "y_sample = y\n",
    "y_pred_sample = y_pred\n",
    "residuals_sample = residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20243378",
   "metadata": {},
   "source": [
    "## 3. Visualisierung 1: Predicted vs Actual\n",
    "\n",
    "Die wichtigste Visualisierung für Regression - zeigt wie gut Predictions mit echten Werten übereinstimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter Plot: Predicted vs Actual\n",
    "axes[0].scatter(y_sample, y_pred_sample, alpha=0.3, s=10)\n",
    "axes[0].plot([y_sample.min(), y_sample.max()], [y_sample.min(), y_sample.max()], 'r--', lw=2, label='Perfekte Vorhersage')\n",
    "axes[0].set_xlabel('Tatsächliche Service Time (Minuten)', fontsize=12)\n",
    "axes[0].set_ylabel('Vorhergesagte Service Time (Minuten)', fontsize=12)\n",
    "axes[0].set_title(f'Predicted vs Actual Values (Sample: {len(y_sample):,} Punkte)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Text mit Metriken\n",
    "textstr = f'RMSE = {rmse:.2f}\\nMAE = {mae:.2f}\\nR² = {r2:.3f}'\n",
    "axes[0].text(0.05, 0.95, textstr, transform=axes[0].transAxes, fontsize=11,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Hexbin Plot (für dichte Bereiche besser sichtbar)\n",
    "hexbin = axes[1].hexbin(y_sample, y_pred_sample, gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "axes[1].plot([y_sample.min(), y_sample.max()], [y_sample.min(), y_sample.max()], 'b--', lw=2, label='Perfekte Vorhersage')\n",
    "axes[1].set_xlabel('Tatsächliche Service Time (Minuten)', fontsize=12)\n",
    "axes[1].set_ylabel('Vorhergesagte Service Time (Minuten)', fontsize=12)\n",
    "axes[1].set_title('Predicted vs Actual (Density)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "plt.colorbar(hexbin, ax=axes[1], label='Anzahl Datenpunkte')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_predicted_vs_actual.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✓ Predicted vs Actual Plot erstellt und gespeichert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6b919",
   "metadata": {},
   "source": [
    "## 4. Visualisierung 2: Residuals (Fehler) Analyse\n",
    "\n",
    "Residuals = Actual - Predicted. Zeigt systematische Fehler im Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08645a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Residuals vs Predicted\n",
    "axes[0, 0].scatter(y_pred_sample, residuals_sample, alpha=0.3, s=10)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 0].set_xlabel('Vorhergesagte Service Time (Minuten)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals (Actual - Predicted)', fontsize=11)\n",
    "axes[0, 0].set_title('Residuals vs Predicted Values', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals Histogram\n",
    "axes[0, 1].hist(residuals_sample, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(x=0, color='r', linestyle='--', lw=2, label='Zero Error')\n",
    "axes[0, 1].axvline(x=residuals_sample.mean(), color='g', linestyle='--', lw=2, label=f'Mean: {residuals_sample.mean():.2f}')\n",
    "axes[0, 1].set_xlabel('Residuals (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Häufigkeit', fontsize=11)\n",
    "axes[0, 1].set_title('Verteilung der Residuals', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Q-Q Plot (prüft Normalverteilung der Fehler)\n",
    "from scipy import stats\n",
    "stats.probplot(residuals_sample, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot (Normalverteilung der Residuals)', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Absolute Errors\n",
    "abs_errors_sample = np.abs(residuals_sample)\n",
    "axes[1, 1].scatter(y_pred_sample, abs_errors_sample, alpha=0.3, s=10)\n",
    "axes[1, 1].axhline(y=mae, color='r', linestyle='--', lw=2, label=f'MAE: {mae:.2f}')\n",
    "axes[1, 1].set_xlabel('Vorhergesagte Service Time (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Absolute Errors (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_title('Absolute Errors vs Predicted', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_residuals_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✓ Residuals Analyse Plot erstellt und gespeichert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b0b47",
   "metadata": {},
   "source": [
    "## 5. Visualisierung 3: Error Distribution by Ranges\n",
    "\n",
    "Zeigt ob das Model für bestimmte Service Time Bereiche besser/schlechter performt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Time in Bereiche einteilen\n",
    "y_sample_series = pd.Series(y_sample).reset_index(drop=True)\n",
    "bins = [0, 5, 10, 15, 20, 25, 30, 100]\n",
    "labels = ['0-5', '5-10', '10-15', '15-20', '20-25', '25-30', '30+']\n",
    "time_ranges = pd.cut(y_sample_series, bins=bins, labels=labels)\n",
    "\n",
    "# DataFrame für Analyse\n",
    "error_df = pd.DataFrame({\n",
    "    'actual': y_sample_series,\n",
    "    'predicted': y_pred_sample,\n",
    "    'abs_error': np.abs(residuals_sample),\n",
    "    'time_range': time_ranges\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. MAE by Time Range\n",
    "mae_by_range = error_df.groupby('time_range')['abs_error'].mean()\n",
    "axes[0, 0].bar(range(len(mae_by_range)), mae_by_range.values, alpha=0.7, color='steelblue')\n",
    "axes[0, 0].axhline(y=mae, color='r', linestyle='--', lw=2, label=f'Gesamt MAE: {mae:.2f}')\n",
    "axes[0, 0].set_xticks(range(len(mae_by_range)))\n",
    "axes[0, 0].set_xticklabels(mae_by_range.index, rotation=45)\n",
    "axes[0, 0].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Mean Absolute Error (MAE)', fontsize=11)\n",
    "axes[0, 0].set_title('MAE nach Service Time Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Boxplot Errors by Range\n",
    "error_df.boxplot(column='abs_error', by='time_range', ax=axes[0, 1])\n",
    "axes[0, 1].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Absolute Error (Minuten)', fontsize=11)\n",
    "axes[0, 1].set_title('Error Distribution nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].get_figure().suptitle('')\n",
    "plt.setp(axes[0, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# 3. Sample Count by Range\n",
    "count_by_range = error_df.groupby('time_range').size()\n",
    "axes[1, 0].bar(range(len(count_by_range)), count_by_range.values, alpha=0.7, color='lightcoral')\n",
    "axes[1, 0].set_xticks(range(len(count_by_range)))\n",
    "axes[1, 0].set_xticklabels(count_by_range.index, rotation=45)\n",
    "axes[1, 0].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Anzahl Samples', fontsize=11)\n",
    "axes[1, 0].set_title('Datenverteilung nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. R² by Range\n",
    "r2_by_range = error_df.groupby('time_range').apply(\n",
    "    lambda x: r2_score(x['actual'], x['predicted']) if len(x) > 1 else 0\n",
    ")\n",
    "axes[1, 1].bar(range(len(r2_by_range)), r2_by_range.values, alpha=0.7, color='mediumseagreen')\n",
    "axes[1, 1].axhline(y=r2, color='r', linestyle='--', lw=2, label=f'Gesamt R²: {r2:.3f}')\n",
    "axes[1, 1].set_xticks(range(len(r2_by_range)))\n",
    "axes[1, 1].set_xticklabels(r2_by_range.index, rotation=45)\n",
    "axes[1, 1].set_xlabel('Service Time Range (Minuten)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('R² Score', fontsize=11)\n",
    "axes[1, 1].set_title('R² Score nach Bereichen', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_error_by_ranges.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✓ Error Distribution by Ranges Plot erstellt und gespeichert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbb5e8",
   "metadata": {},
   "source": [
    "## 6. Visualisierung 4: Feature Importance vs Error\n",
    "\n",
    "Analysiert ob schlechte Predictions mit bestimmten Features zusammenhängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926861e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors zu Features hinzufügen\n",
    "X_with_errors = X_sample.copy()\n",
    "X_with_errors['abs_error'] = np.abs(residuals_sample)\n",
    "X_with_errors['predicted'] = y_pred_sample\n",
    "X_with_errors['actual'] = y_sample_series.values\n",
    "\n",
    "# Top 6 wichtigste Features\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance.head(6)['feature'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(top_features):\n",
    "        axes[idx].scatter(X_with_errors[feature], X_with_errors['abs_error'], alpha=0.3, s=10)\n",
    "        axes[idx].axhline(y=mae, color='r', linestyle='--', lw=1, alpha=0.5)\n",
    "        axes[idx].set_xlabel(feature, fontsize=10)\n",
    "        axes[idx].set_ylabel('Absolute Error (Min)', fontsize=10)\n",
    "        axes[idx].set_title(f'{feature} vs Error', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'model_features_vs_error.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n✓ Features vs Error Plot erstellt und gespeichert\")\n",
    "else:\n",
    "    print(\"\\n⚠ Model hat keine feature_importances_ (z.B. bei Linear Regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dbd34",
   "metadata": {},
   "source": [
    "## 7. Visualisierung 5: Error Percentiles\n",
    "\n",
    "Zeigt die Verteilung der Errors in Perzentilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ed1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Cumulative Error Distribution\n",
    "sorted_abs_errors = np.sort(np.abs(residuals_sample))\n",
    "cumulative = np.arange(1, len(sorted_abs_errors) + 1) / len(sorted_abs_errors)\n",
    "\n",
    "axes[0].plot(sorted_abs_errors, cumulative * 100, linewidth=2)\n",
    "axes[0].axvline(x=mae, color='r', linestyle='--', lw=2, label=f'MAE: {mae:.2f}')\n",
    "axes[0].axhline(y=50, color='g', linestyle='--', lw=1, alpha=0.5, label='Median (50%)')\n",
    "axes[0].axhline(y=90, color='orange', linestyle='--', lw=1, alpha=0.5, label='90% Percentile')\n",
    "axes[0].set_xlabel('Absolute Error (Minuten)', fontsize=12)\n",
    "axes[0].set_ylabel('Cumulative Percentage', fontsize=12)\n",
    "axes[0].set_title('Kumulative Error Verteilung', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error Percentiles Table\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "error_percentiles = [np.percentile(np.abs(residuals_sample), p) for p in percentiles]\n",
    "\n",
    "axes[1].bar(range(len(percentiles)), error_percentiles, alpha=0.7, color='skyblue')\n",
    "axes[1].set_xticks(range(len(percentiles)))\n",
    "axes[1].set_xticklabels([f'{p}%' for p in percentiles])\n",
    "axes[1].set_xlabel('Percentile', fontsize=12)\n",
    "axes[1].set_ylabel('Absolute Error (Minuten)', fontsize=12)\n",
    "axes[1].set_title('Error Percentiles', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for i, v in enumerate(error_percentiles):\n",
    "    axes[1].text(i, v + 0.3, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'model_error_percentiles.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n✓ Error Percentiles Plot erstellt und gespeichert\")\n",
    "\n",
    "# Percentiles ausgeben\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERROR PERCENTILES\")\n",
    "print(\"=\" * 60)\n",
    "for p, val in zip(percentiles, error_percentiles):\n",
    "    print(f\"{p:3d}% der Predictions haben einen Fehler <= {val:.2f} Minuten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571091c5",
   "metadata": {},
   "source": [
    "## 8. Zusammenfassung\n",
    "\n",
    "Übersicht aller erstellten Visualisierungen und Erkenntnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MODEL EVALUATION - ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. ERSTELLTE VISUALISIERUNGEN:\")\n",
    "print(\"   ✓ Predicted vs Actual (Scatter + Density)\")\n",
    "print(\"   ✓ Residuals Analyse (4 Plots)\")\n",
    "print(\"   ✓ Error Distribution by Time Ranges\")\n",
    "print(\"   ✓ Features vs Error Analysis\")\n",
    "print(\"   ✓ Error Percentiles & Cumulative Distribution\")\n",
    "\n",
    "print(\"\\n2. PERFORMANCE METRIKEN (5% Sample):\")\n",
    "print(f\"   - RMSE: {rmse:.4f} Minuten\")\n",
    "print(f\"   - MAE:  {mae:.4f} Minuten\")\n",
    "print(f\"   - R²:   {r2:.4f}\")\n",
    "\n",
    "print(\"\\n3. ERROR VERTEILUNG:\")\n",
    "print(f\"   - Median Error: {np.median(np.abs(residuals_sample)):.2f} Minuten\")\n",
    "print(f\"   - 90% der Fehler <= {np.percentile(np.abs(residuals_sample), 90):.2f} Minuten\")\n",
    "print(f\"   - Max Error: {np.max(np.abs(residuals_sample)):.2f} Minuten\")\n",
    "\n",
    "print(\"\\n4. INTERPRETATION:\")\n",
    "if r2 > 0.8:\n",
    "    print(\"   ✓ EXCELLENT: Model erklärt > 80% der Varianz\")\n",
    "elif r2 > 0.6:\n",
    "    print(\"   ✓ GOOD: Model erklärt > 60% der Varianz\")\n",
    "elif r2 > 0.4:\n",
    "    print(\"   ⚠ FAIR: Model erklärt > 40% der Varianz\")\n",
    "else:\n",
    "    print(\"   ❌ POOR: Model erklärt < 40% der Varianz\")\n",
    "\n",
    "print(f\"\\n   Im Durchschnitt weicht die Vorhersage um {mae:.2f} Minuten vom echten Wert ab.\")\n",
    "\n",
    "print(\"\\n5. NÄCHSTE SCHRITTE:\")\n",
    "print(\"   - Residuals Analyse prüfen: Gibt es systematische Fehler?\")\n",
    "print(\"   - Q-Q Plot prüfen: Sind Fehler normalverteilt?\")\n",
    "print(\"   - Error by Ranges prüfen: Performt Model überall gleich gut?\")\n",
    "print(\"   - Features vs Error prüfen: Welche Features verursachen große Fehler?\")\n",
    "\n",
    "print(\"\\n6. OPTIMIERUNG:\")\n",
    "print(f\"   ✓ Verwendet nur {len(X_sample):,} Sample ({len(X_sample)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ✓ Predictions & Plots ultra-schnell!\")\n",
    "print(f\"   ✓ Gesamt-Ausführungszeit: {time.time()-start_time:.1f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ EVALUATION ABGESCHLOSSEN\")\n",
    "print(f\"✓ Alle Plots gespeichert in: {PLOTS_DIR}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
